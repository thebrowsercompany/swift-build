#!/usr/bin/python3

# This script transforms the csv data generated by bloaty into
# data that is ready to uploading to BigQuery. It makes various
# modifications including adding columns for the toolchain version
# and runtime environments, and normalizing toolchain filenames.

import argparse
import os
import pandas as pd
from bigquery_schema import BQ_SCHEMA

def strip_column_prefix(csv_data, column_name, prefix):
    csv_data[column_name] = csv_data[column_name].apply(lambda x: x[len(prefix):])

def add_column(csv_data, column_name, column_value):
    allow_duplicate_column_labels = False
    csv_data.insert(0, column_name, column_value, allow_duplicate_column_labels)

def rename_column(csv_data, old_name, new_name):
    csv_data.rename(columns={old_name: new_name}, inplace=True)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('bloaty_csv_output', type=str, help='The path to the csv file generated by bloaty')
    parser.add_argument('output_csv', type=str, help='Where to write the generated csv file')
    
    req_group = parser.add_argument_group('required flags', 'Additional properties that help slice and group data in BigQuery')
    req_group.add_argument('--toolchain_version', type=str, help='The toolchain version that corresponds to the input data')
    req_group.add_argument('--environment', type=str, default='debug', help='The name of the environment where this data was generated')
    
    opt_group = parser.add_argument_group('optional flags')
    opt_group.add_argument('--strip_inputfiles_prefix', type=str, help='A prefix to strip from the inputfiles column')
    args = parser.parse_args()

    csv_data = pd.read_csv(args.bloaty_csv_output)

    if args.strip_inputfiles_prefix:
        strip_inputfiles_prefix = os.path.abspath(args.strip_inputfiles_prefix) + os.sep
        strip_column_prefix(csv_data, 'inputfiles', strip_inputfiles_prefix)
    add_column(csv_data, 'toolchain_version', args.toolchain_version)
    add_column(csv_data, 'environment', args.environment)
    add_column(csv_data, 'target_os', 'windows')
    add_column(csv_data, 'target_arch', 'amd64')
    rename_column(csv_data, 'inputfiles', 'filename')
    rename_column(csv_data, 'segments', 'segment')
    
    # Reorder the columns to match the order specified in BQ_SCHEMA
    column_order = [ schema_field.name for schema_field in BQ_SCHEMA ]
    csv_data = csv_data[column_order]

    csv_data.to_csv(args.output_csv, index=False)

main()
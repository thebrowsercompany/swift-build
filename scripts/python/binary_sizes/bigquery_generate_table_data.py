#!/usr/bin/python3

# This script transforms the csv data generated by bloaty into data that is
# ready to upload to BigQuery.
#
# The input csv should have the following header columns:
#
#  filesize
#  inputfiles
#  segment
#  vmsize
#
# The output csv has these columns, in the order specified by bigquery_schema.BQ_SCHEMA:
#
#  creation_time - when the release was created
#  environment - a tag to associate with the new table row
#  filename - renamed from inputfiles
#  filesize - bloaty filesize output
#  segment - bloaty segment output
#  target_os - the Swift toolchain target OS
#  target_arch - the Swift toolchain target architecture
#  vmsize - bloaty vmsize output.

import argparse
import os
import pandas as pd
from datetime import datetime
from bigquery_schema import BQ_SCHEMA

def strip_prefix_from_column_values(csv_data, column_name, prefix):
    csv_data[column_name] = csv_data[column_name].apply(lambda x: x[len(prefix):])

def add_column(csv_data, column_name, column_value):
    allow_duplicate_column_labels = False
    csv_data.insert(0, column_name, column_value, allow_duplicate_column_labels)

def rename_column(csv_data, old_name, new_name):
    csv_data.rename(columns={old_name: new_name}, inplace=True)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('bloaty_csv_output', type=str, help='The path to the csv file generated by bloaty')
    parser.add_argument('output_csv', type=str, help='Where to write the generated csv file')

    req_group = parser.add_argument_group('required flags', 'Additional properties that help slice and group data in BigQuery')
    req_group.add_argument('--toolchain-version', type=str, help='The toolchain version that corresponds to the input data')
    req_group.add_argument('--toolchain-arch', type=str, help='The toolchain target architecture')

    opt_group = parser.add_argument_group('optional flags')
    opt_group.add_argument('--creation-time', type=str, help='timestamp when the release was created formatted as YYYY-MM-DD')
    opt_group.add_argument('--environment', type=str, default='debug', help='The name of the environment where this data was generated')
    opt_group.add_argument('--strip-inputfiles-prefix', type=str, help='A prefix to strip from the inputfiles column')
    args = parser.parse_args()

    csv_data = pd.read_csv(args.bloaty_csv_output)

    creation_time = args.creation_time
    if len(creation_time) == 0:
        creation_time = datetime.now().replace(microsecond=0).isoformat()

    if args.strip_inputfiles_prefix:
        strip_inputfiles_prefix = os.path.abspath(args.strip_inputfiles_prefix) + os.sep
        strip_prefix_from_column_values(csv_data, 'inputfiles', strip_inputfiles_prefix)
    add_column(csv_data, 'toolchain_version', args.toolchain_version)
    add_column(csv_data, 'environment', args.environment)
    add_column(csv_data, 'target_os', 'windows')
    add_column(csv_data, 'target_arch', args.toolchain_arch)
    add_column(csv_data, 'creation_time', creation_time)
    rename_column(csv_data, 'inputfiles', 'filename')
    rename_column(csv_data, 'segments', 'segment')

    # Reorder the columns to match the order specified in BQ_SCHEMA.
    # Otherwise bigquery fails to parse the columns.
    column_order = [ schema_field.name for schema_field in BQ_SCHEMA ]
    csv_data = csv_data[column_order]

    csv_data.to_csv(args.output_csv, index=False)

main()
